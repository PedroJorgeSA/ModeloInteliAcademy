{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RgUE2bsuyPc",
        "outputId": "9d2882e7-1f41-41ea-cb13-290ca600183a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados de treino carregados com 98872 linhas e 18 colunas.\n",
            "Dados de teste carregados com 5000 linhas e 17 colunas.\n",
            "Número de features numéricas: 16\n",
            "Número de features categóricas: 5\n",
            "Modelo: LogisticRegression | Acurácia no conjunto de validação: 0.6542\n",
            "Modelo: RandomForest | Acurácia no conjunto de validação: 0.7170\n",
            "Modelo final treinado com todos os dados de treino.\n",
            "\n",
            "Top 10 features mais importantes:\n",
            "                feature  importance\n",
            "     tempo_como_cliente    0.192243\n",
            "            total_gasto    0.140764\n",
            "tempo_medio_atendimento    0.120859\n",
            "           valor_mensal    0.114255\n",
            "                  idade    0.103722\n",
            "      suporte_contatado    0.048589\n",
            "       chamados_abertos    0.040121\n",
            "      atrasos_pagamento    0.039276\n",
            "            reclamacoes    0.025538\n",
            " forma_pagamento_Boleto    0.014069\n",
            "\n",
            "Arquivo \"resultado_nome_sobrenome.csv\" gerado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "## 1. Importação das Bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# ## 2. Carregamento dos Dados\n",
        "train = pd.read_csv('dados_clientes.csv')\n",
        "test = pd.read_csv('desafio.csv')\n",
        "\n",
        "print(f'Dados de treino carregados com {train.shape[0]} linhas e {train.shape[1]} colunas.')\n",
        "print(f'Dados de teste carregados com {test.shape[0]} linhas e {test.shape[1]} colunas.')\n",
        "\n",
        "# ## 3. Pré-processamento e Engenharia de Features\n",
        "\n",
        "import ast\n",
        "\n",
        "def processa_produtos(df):\n",
        "    produtos_possiveis = ['Produto A', 'Produto B', 'Produto C', 'Produto D', 'Produto E', 'Produto F']\n",
        "    def parse_produtos(x):\n",
        "        if isinstance(x, list):\n",
        "            return x\n",
        "        try:\n",
        "            return ast.literal_eval(x)\n",
        "        except:\n",
        "            return []\n",
        "    df['produtos_assinados'] = df['produtos_assinados'].apply(parse_produtos)\n",
        "    for prod in produtos_possiveis:\n",
        "        df[f'has_{prod}'] = df['produtos_assinados'].apply(lambda lst: int(prod in lst))\n",
        "    df['num_produtos'] = df['produtos_assinados'].apply(len)\n",
        "    df = df.drop('produtos_assinados', axis=1)\n",
        "    return df\n",
        "\n",
        "train = processa_produtos(train)\n",
        "test = processa_produtos(test)\n",
        "\n",
        "# ## 4. Seleção de Features e Target\n",
        "\n",
        "target = 'churn'\n",
        "id_col = 'id_cliente'\n",
        "features = [col for col in train.columns if col not in [target, id_col, 'servicos_assinados']]\n",
        "\n",
        "X = train[features]\n",
        "y = train[target]\n",
        "X_test = test[features]\n",
        "test_ids = test[id_col]\n",
        "\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f'Número de features numéricas: {len(numeric_features)}')\n",
        "print(f'Número de features categóricas: {len(categorical_features)}')\n",
        "\n",
        "# ## 5. Pipeline de Pré-processamento\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_features),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]), categorical_features)\n",
        "])\n",
        "\n",
        "# ## 6. Treinamento e Avaliação de Modelos\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.2, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', clf)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    score = pipe.score(X_val, y_val)\n",
        "    print(f'Modelo: {name} | Acurácia no conjunto de validação: {score:.4f}')\n",
        "\n",
        "\n",
        "## 7. Treinamento do Modelo Final (Random Forest)\n",
        "\n",
        "final_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42))\n",
        "])\n",
        "final_model.fit(X, y)\n",
        "print('Modelo final treinado com todos os dados de treino.')\n",
        "\n",
        "## 8. Importância das Features\n",
        "\n",
        "feature_names_num = numeric_features\n",
        "feature_names_cat = list(final_model.named_steps['preprocessor']\n",
        "                        .named_transformers_['cat']\n",
        "                        .named_steps['onehot']\n",
        "                        .get_feature_names_out(categorical_features))\n",
        "\n",
        "feature_names = feature_names_num + feature_names_cat\n",
        "\n",
        "importances = final_model.named_steps['classifier'].feature_importances_\n",
        "\n",
        "feat_imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
        "feat_imp_df = feat_imp_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "print('\\nTop 10 features mais importantes:')\n",
        "print(feat_imp_df.head(10).to_string(index=False))\n",
        "\n",
        "\n",
        "## 9. Previsão no Conjunto de Teste e Geração do CSV\n",
        "\n",
        "predictions = final_model.predict(X_test)\n",
        "\n",
        "resultado = pd.DataFrame({\n",
        "    'Id': test_ids,\n",
        "    'Target': predictions\n",
        "})\n",
        "\n",
        "resultado.to_csv('pedro.soares', index=False)\n",
        "print('\\nArquivo \"pedro.soares\" gerado com sucesso.')\n"
      ]
    }
  ]
}